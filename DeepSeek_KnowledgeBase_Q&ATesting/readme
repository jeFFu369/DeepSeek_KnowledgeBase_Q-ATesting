# BBS HR Knowledge Base App

## Overview

The **BBS HR Knowledge Base App** is a web-based application designed to help users manage and query a collection of documents (PDFs and DOCX files) using AI-powered natural language processing (NLP). The app allows users to upload documents, extract their content, and store them in a MongoDB database. Users can then ask questions related to the uploaded documents, and the app will provide answers by leveraging a local AI model. Auto-Detect Knowledge Base, that analyze the query using embeddings or TF-IDF to determine which knowledge base is most relevant.
Automatically select the best-matching knowledge base and notify the user (e.g., "I found the most relevant document for your question: [Filename].").


Key features:
- Upload and manage PDF/DOCX documents.
- Extract text from documents and split it into chunks for efficient querying.
- Store document chunks and their embeddings in MongoDB for semantic search.
- Auto-detect the most relevant document for a given question.
- Query the knowledge base using a local AI model for accurate and context-aware responses.

---

## Table of Contents

1. [Prerequisites](#prerequisites)
2. [Installation](#installation)
3. [Project Structure](#project-structure)
4. [Configuration](#configuration)
5. [Usage](#usage)
   - [Running the Application](#running-the-application)
   - [Uploading Documents](#uploading-documents)
   - [Querying the Knowledge Base](#querying-the-knowledge-base)
   - [Viewing Uploaded Files](#viewing-uploaded-files)
   - [Deleting Files](#deleting-files)
6. [API Endpoints](#api-endpoints)
7. [Dependencies](#dependencies)
8. [Contributing](#contributing)
9. [License](#license)

---

## Prerequisites

Before running the application, ensure you have the following installed:

- Python 3.8 or higher
- MongoDB (local or cloud instance)
- A local AI model server running at `http://localhost:11434/api/generate` (e.g., Ollama with a model like `deepseek-r1:8b`)
- NLTK (for sentence tokenization)

---

## Installation

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/your-repo/bbs-hr-knowledge-base.git
   cd bbs-hr-knowledge-base
   ```

2. **Set Up a Virtual Environment** (optional but recommended):
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Download NLTK Data**:
   Run the following command to download the required NLTK data for sentence tokenization:
   ```python
   python -c "import nltk; nltk.download('punkt')"
   ```

---

## Project Structure

```
bbs-hr-knowledge-base/
├── main.py                  # Main FastAPI application
├── requirements.txt        # List of Python dependencies
├── uploads/                # Directory for storing uploaded files
├── templates/              # Jinja2 HTML templates for the frontend
├── static/                 # Static files (if theres CSS, JS, etc.)
├── README.md               # This file
└── .env                    # Environment variables (optional)
```

---

## Configuration

1. **MongoDB Connection**:
   Update the MongoDB URI in the `main.py` file to point to your MongoDB instance:
   ```python
   client = pymongo.MongoClient(
       "mongodb+srv://<username>:<password>@<cluster-url>/?retryWrites=true&w=majority&appName=<app-name>",
       connect=False
   )
   ```

2. **AI Model Server**:
   Ensure the local AI model server is running at `http://localhost:11434/api/generate`. Update the URL in the `query_local_model` function if necessary.

3. **Environment Variables** (Optional):
   Use a `.env` file to store sensitive information like MongoDB credentials.

---

## Usage

### Running the Application

Start the FastAPI application using Uvicorn:
```bash
uvicorn main:app --reload
```

The webapp will be accessible at `http://127.0.0.1:8000`.

### Uploading Documents

1. Navigate to the **Knowledge Base** section in the app.
2. Use the upload form to select one or more PDF/DOCX files.
3. Click **Upload Knowledge Base** to process and store the files.

### Querying the Knowledge Base

1. Navigate to the **Chat with AI** section.
2. Enter your question in the input field.
3. Optionally, select a specific document from the dropdown menu.
4. Click **Submit Question** to get an AI-generated response.

If no document is selected, the app will automatically detect the most relevant document for your question.

### Viewing Uploaded Files

Navigate to the **Knowledge Base** section to view a list of uploaded files and their contents.

### Deleting Files

To delete a file, click the **Delete** button next to the file in the **Knowledge Base** section.

---

## API Endpoints

| Endpoint             | Method | Description                                      |
|----------------------|--------|--------------------------------------------------|
| `/`                  | GET    | Home page                                        |
| `/files`             | GET    | Retrieve a list of uploaded files                |
| `/upload`            | POST   | Upload new documents                             |
| `/query`             | POST   | Query the knowledge base                         |
| `/view/{filename}`   | GET    | View the content of a specific file              |
| `/delete/{filename}` | DELETE | Delete a file from the database and filesystem   |

---

## Dependencies

Install the required dependencies using the following command:
```bash
pip install -r requirements.txt
```

List of dependencies:
- `fastapi`
- `uvicorn`
- `pymongo`
- `sentence-transformers`
- `numpy`
- `sklearn`
- `nltk`
- `requests`
- `werkzeug`

---

## Contributing

Contributions are welcome! To contribute:
1. Fork the repository.
2. Create a new branch for your feature/fix.
3. Submit a pull request with a detailed description of your changes.

---

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

Let me know if you'd like to add or modify anything in the README!